{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting paddle-quantum\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/c6/6a/36e44a9076eec5386765c9db7f3e1204456959af6f65051ebfba80049219/paddle_quantum-2.0.0-py3-none-any.whl (67kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 15.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddle-quantum) (4.36.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddle-quantum) (2.2.3)\n",
      "Collecting paddlepaddle>=2.0.1 (from paddle-quantum)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/89/ad/c1705be6b25a7f0413c4931636c6d1a9752f4383bd00eb62c353be9133f7/paddlepaddle-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (208.1MB)\n",
      "\u001b[K     |████████████████████████████████| 208.1MB 8.9MB/s eta 0:00:014     |█████████████████████████████▏  | 189.6MB 8.3MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddle-quantum) (2.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddle-quantum) (1.3.0)\n",
      "Collecting interval (from paddle-quantum)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/b3/2d/b337afbd232ea1ea9c38401135054bf763e7930ea5e2e49bc39af35c3443/interval-1.0.0.tar.bz2\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddle-quantum) (2019.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddle-quantum) (2.4.2)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddle-quantum) (1.15.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddle-quantum) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddle-quantum) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddle-quantum) (1.16.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddle-quantum) (2.8.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle>=2.0.1->paddle-quantum) (2.22.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle>=2.0.1->paddle-quantum) (7.1.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle>=2.0.1->paddle-quantum) (4.4.0)\n",
      "Requirement already satisfied: astor in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle>=2.0.1->paddle-quantum) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle>=2.0.1->paddle-quantum) (3.14.0)\n",
      "Requirement already satisfied: gast>=0.3.3; platform_system != \"Windows\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle>=2.0.1->paddle-quantum) (0.3.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->paddle-quantum) (41.4.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle>=2.0.1->paddle-quantum) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle>=2.0.1->paddle-quantum) (1.25.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle>=2.0.1->paddle-quantum) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle>=2.0.1->paddle-quantum) (3.0.4)\n",
      "Building wheels for collected packages: interval\n",
      "  Building wheel for interval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for interval: filename=interval-1.0.0-cp37-none-any.whl size=14266 sha256=eb5b25225c29525a4702fbe738a1932479e55b47a9b0948c437dec1aad172a79\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/aa/fd/f0/28a65289ea3a10ea744cfe6d2393605383772be2ab2b75967e\n",
      "Successfully built interval\n",
      "Installing collected packages: paddlepaddle, interval, paddle-quantum\n",
      "  Found existing installation: paddlepaddle 1.8.4\n",
      "    Uninstalling paddlepaddle-1.8.4:\n",
      "      Successfully uninstalled paddlepaddle-1.8.4\n",
      "Successfully installed interval-1.0.0 paddle-quantum-2.0.0 paddlepaddle-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install paddle-quantum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "2021-03-13 23:06:43,180 - INFO - font search path ['/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/afm', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\n",
      "2021-03-13 23:06:43,534 - INFO - generated new fontManager\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "import paddle\r\n",
    "from paddle import matmul, transpose, trace\r\n",
    "from paddle_quantum.circuit import UAnsatz\r\n",
    "from paddle_quantum.utils import dagger, random_pauli_str_generator, pauli_str_to_matrix\r\n",
    "from paddle_quantum.state import vec, vec_random, density_op, density_op_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n",
      "[[ 6.123234e-17+0.j -1.000000e+00+0.j]\n",
      " [ 1.000000e+00+0.j  6.123234e-17+0.j]]\n",
      "[[ 0.70710678  0.70710678]\n",
      " [-0.70710678  0.70710678]]\n",
      "0.7071067811865475\n"
     ]
    }
   ],
   "source": [
    "import math\r\n",
    "u = np.array([[1,-1],\r\n",
    "             [1, 1]])\r\n",
    "u = 1/math.sqrt(2)*u\r\n",
    "print(u)\r\n",
    "\r\n",
    "theta = np.array([np.pi])\r\n",
    "theta = paddle.to_tensor(theta)\r\n",
    "num_qubits = 1\r\n",
    "cir = UAnsatz(num_qubits)\r\n",
    "\r\n",
    "which_qubit = 0\r\n",
    "cir.ry(theta,which_qubit)\r\n",
    "\r\n",
    "print(cir.U.numpy())\r\n",
    "x = np.transpose(cir.U.numpy().real)\r\n",
    "x = np.matmul(u,x)\r\n",
    "print(x)\r\n",
    "F = 1/2*x.trace()\r\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0   loss: 0.2543\n",
      "iter: 5   loss: 0.0453\n",
      "iter: 10   loss: 0.0139\n",
      "iter: 15   loss: 0.0211\n",
      "iter: 20   loss: 0.0027\n",
      "iter: 25   loss: 0.0088\n",
      "iter: 30   loss: 0.0002\n",
      "iter: 35   loss: 0.0036\n",
      "iter: 40   loss: 0.0001\n",
      "iter: 45   loss: 0.0010\n",
      "iter: 50   loss: 0.0004\n",
      "iter: 55   loss: 0.0001\n",
      "iter: 60   loss: 0.0003\n",
      "iter: 65   loss: 0.0000\n",
      "iter: 70   loss: 0.0000\n",
      "iter: 75   loss: 0.0001\n",
      "iter: 80   loss: 0.0000\n",
      "iter: 85   loss: 0.0000\n",
      "iter: 90   loss: 0.0000\n",
      "iter: 95   loss: 0.0000\n",
      "iter: 100   loss: 0.0000\n",
      "iter: 105   loss: 0.0000\n",
      "iter: 110   loss: 0.0000\n",
      "iter: 115   loss: 0.0000\n",
      "iter: 120   loss: 0.0000\n",
      "iter: 125   loss: 0.0000\n",
      "iter: 130   loss: 0.0000\n",
      "iter: 135   loss: 0.0000\n",
      "iter: 140   loss: 0.0000\n",
      "iter: 145   loss: 0.0000\n",
      "iter: 150   loss: 0.0000\n",
      "iter: 155   loss: 0.0000\n",
      "iter: 160   loss: 0.0000\n",
      "iter: 165   loss: 0.0000\n",
      "iter: 170   loss: 0.0000\n",
      "iter: 175   loss: 0.0000\n",
      "iter: 180   loss: 0.0000\n",
      "iter: 185   loss: 0.0000\n",
      "iter: 190   loss: 0.0000\n",
      "iter: 195   loss: 0.0000\n",
      "3.739453191542452e-11\n",
      "Parameter containing:\n",
      "Tensor(shape=[1], dtype=float64, place=CPUPlace, stop_gradient=False,\n",
      "       [1.57082714])\n"
     ]
    }
   ],
   "source": [
    "#单量子比特近似\r\n",
    "\r\n",
    "import math\r\n",
    "import numpy as np\r\n",
    "import paddle\r\n",
    "from paddle import matmul, transpose, trace\r\n",
    "from paddle_quantum.circuit import UAnsatz\r\n",
    "from paddle_quantum.utils import dagger, random_pauli_str_generator, pauli_str_to_matrix\r\n",
    "from paddle_quantum.state import vec, vec_random, density_op, density_op_random\r\n",
    "theta_size = 1\r\n",
    "num_qubits = 1\r\n",
    "ITR = 200\r\n",
    "LR=0.5\r\n",
    "SEED = 1\r\n",
    "paddle.seed(SEED)\r\n",
    "\r\n",
    "def U_theta(theta,num_qubits):\r\n",
    "    cir = UAnsatz(num_qubits)\r\n",
    "    which_qubit = 0\r\n",
    "    cir.ry(theta[0],which_qubit)\r\n",
    "    return cir.U\r\n",
    "\r\n",
    "class Optimization_exl(paddle.nn.Layer):\r\n",
    "    def __init__(self,shape,dtype='float64'):\r\n",
    "        super(Optimization_exl,self).__init__()\r\n",
    "        self.u = paddle.to_tensor(1/math.sqrt(2)* np.array([[1,-1],[1, 1]]))\r\n",
    "        self.theta = self.create_parameter(shape=shape,\r\n",
    "                                            default_initializer = paddle.nn.initializer.Uniform(low=0,high=2*np.pi),\r\n",
    "                                            dtype=dtype,is_bias=False)\r\n",
    "    \r\n",
    "    def forward(self):\r\n",
    "        U = U_theta(self.theta,num_qubits)\r\n",
    "        U_dagger = dagger(U)\r\n",
    "        loss = 1-(0.5*paddle.real(trace(matmul(self.u,U_dagger)))[0])\r\n",
    "        return loss\r\n",
    "    \r\n",
    "    def result(self):\r\n",
    "        return self.theta\r\n",
    "\r\n",
    "loss_list = []\r\n",
    "parameter_list = []\r\n",
    "myLayer = Optimization_exl([theta_size])\r\n",
    "opt = paddle.optimizer.Adam(learning_rate=LR,parameters=myLayer.parameters())\r\n",
    "\r\n",
    "for itr in range(ITR):\r\n",
    "    loss = myLayer()[0]\r\n",
    "    loss.backward()\r\n",
    "    opt.minimize(loss)\r\n",
    "    opt.clear_grad()\r\n",
    "\r\n",
    "    loss_list.append(loss.numpy()[0])\r\n",
    "    parameter_list.append(myLayer.parameters()[0].numpy())\r\n",
    "    if itr % 5 == 0:\r\n",
    "        print('iter:', itr, '  loss: %.4f' % loss.numpy())\r\n",
    "print(loss_list[-1])\r\n",
    "print(myLayer.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'matmul' from 'paddle' (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2191c77b84f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpaddle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpaddle_quantum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircuit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUAnsatz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpaddle_quantum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_pauli_str_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpauli_str_to_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'matmul' from 'paddle' (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/__init__.py)"
     ]
    }
   ],
   "source": [
    "#双量子门\r\n",
    "\r\n",
    "import math\r\n",
    "import numpy as np\r\n",
    "import paddle\r\n",
    "from paddle import matmul, transpose, trace\r\n",
    "from paddle_quantum.circuit import UAnsatz\r\n",
    "from paddle_quantum.utils import dagger, random_pauli_str_generator, pauli_str_to_matrix\r\n",
    "from paddle_quantum.state import vec, vec_random, density_op, density_op_random\r\n",
    "theta_size = 4\r\n",
    "num_qubits = 2\r\n",
    "ITR = 80\r\n",
    "LR=0.5\r\n",
    "SEED = 1\r\n",
    "paddle.seed(SEED)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def U_theta(theta,num_qubits):\r\n",
    "    cir = UAnsatz(num_qubits)\r\n",
    "    cir.ry(theta[0],0)\r\n",
    "    cir.ry(theta[1],1)\r\n",
    "    cir.cnot([0,1])\r\n",
    "    cir.ry(theta[2],0)\r\n",
    "    cir.ry(theta[3],1)\r\n",
    "    return cir.U\r\n",
    "\r\n",
    "class Optimization_exl(paddle.nn.Layer):\r\n",
    "    def __init__(self,shape,dtype='float64'):\r\n",
    "        super(Optimization_exl,self).__init__()\r\n",
    "        self.u = paddle.to_tensor(np.array([[0.098757, -0.305705, 0.207859, 0.923897],\r\n",
    "                                            [-0.112903, 0.177275, 0.966589, -0.146738],\r\n",
    "                                            [-0.795313, 0.514071, -0.143547, 0.287407],\r\n",
    "                                            [-0.587348, -0.781568, 0.043521, -0.205619 ]]))\r\n",
    "        self.theta = self.create_parameter(shape=shape,\r\n",
    "                                            default_initializer = paddle.nn.initializer.Uniform(low=0,high=2*np.pi),\r\n",
    "                                            dtype=dtype,is_bias=False)\r\n",
    "    \r\n",
    "    def forward(self):\r\n",
    "        U = U_theta(self.theta,num_qubits)\r\n",
    "        U_dagger = dagger(U)\r\n",
    "        loss = 1-(0.25*paddle.real(trace(matmul(self.u,U_dagger)))[0])\r\n",
    "        return loss\r\n",
    "    \r\n",
    "    def result(self):\r\n",
    "        return self.theta\r\n",
    "\r\n",
    "loss_list = []\r\n",
    "parameter_list = []\r\n",
    "myLayer = Optimization_exl([theta_size])\r\n",
    "opt = paddle.optimizer.Adam(learning_rate=LR,parameters=myLayer.parameters())\r\n",
    "\r\n",
    "for itr in range(ITR):\r\n",
    "    loss = myLayer()[0]\r\n",
    "    loss.backward()\r\n",
    "    opt.minimize(loss)\r\n",
    "    opt.clear_grad()\r\n",
    "\r\n",
    "    loss_list.append(loss.numpy()[0])\r\n",
    "    parameter_list.append(myLayer.parameters()[0].numpy())\r\n",
    "    if itr % 5 == 0:\r\n",
    "        print('iter:', itr, '  loss: %.4f' % loss.numpy())\r\n",
    "print(loss_list[-1])\r\n",
    "print(myLayer.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0   loss: 0.8550\n",
      "iter: 5   loss: 0.0763\n",
      "iter: 10   loss: 0.1011\n",
      "iter: 15   loss: 0.0299\n",
      "iter: 20   loss: 0.0472\n",
      "iter: 25   loss: 0.0014\n",
      "iter: 30   loss: 0.0188\n",
      "iter: 35   loss: 0.0034\n",
      "iter: 40   loss: 0.0048\n",
      "iter: 45   loss: 0.0010\n",
      "iter: 50   loss: 0.0026\n",
      "iter: 55   loss: 0.0004\n",
      "iter: 60   loss: 0.0006\n",
      "iter: 65   loss: 0.0002\n",
      "iter: 70   loss: 0.0002\n",
      "iter: 75   loss: 0.0002\n",
      "iter: 80   loss: 0.0000\n",
      "iter: 85   loss: 0.0001\n",
      "iter: 90   loss: 0.0000\n",
      "iter: 95   loss: 0.0000\n",
      "1.5951791803470172e-05\n",
      "Parameter containing:\n",
      "Tensor(shape=[5], dtype=float64, place=CPUPlace, stop_gradient=False,\n",
      "       [-2.31120880,  4.50132263,  5.94368069, -1.46651638,  1.98734749])\n"
     ]
    }
   ],
   "source": [
    "#三量子门\r\n",
    "\r\n",
    "import math\r\n",
    "import numpy as np\r\n",
    "import paddle\r\n",
    "from paddle import matmul, transpose, trace\r\n",
    "from paddle_quantum.circuit import UAnsatz\r\n",
    "from paddle_quantum.utils import dagger, random_pauli_str_generator, pauli_str_to_matrix\r\n",
    "from paddle_quantum.state import vec, vec_random, density_op, density_op_random\r\n",
    "theta_size = 5\r\n",
    "num_qubits = 3\r\n",
    "ITR = 100\r\n",
    "LR=0.5\r\n",
    "SEED = 1\r\n",
    "paddle.seed(SEED)\r\n",
    "path = '飞桨常规赛：量子电路合成/Question_3_Unitary.txt'\r\n",
    "def readfile(path):\r\n",
    "    f = np.loadtxt(path)\r\n",
    "    return f\r\n",
    "\r\n",
    "def U_theta(theta,num_qubits):\r\n",
    "    cir = UAnsatz(num_qubits)\r\n",
    "    cir.ry(theta[0],0)\r\n",
    "    cir.ry(theta[1],1)\r\n",
    "    cir.ry(theta[2],2)\r\n",
    "    cir.cnot([0,1])\r\n",
    "    cir.cnot([1,2])\r\n",
    "    cir.ry(theta[3],0)\r\n",
    "    cir.ry(theta[4],2)\r\n",
    "    return cir.U\r\n",
    "\r\n",
    "class Optimization_exl(paddle.nn.Layer):\r\n",
    "    def __init__(self,shape,dtype='float64'):\r\n",
    "        super(Optimization_exl,self).__init__()\r\n",
    "        f = readfile(path)\r\n",
    "        self.u = paddle.to_tensor(f)\r\n",
    "        self.theta = self.create_parameter(shape=shape,\r\n",
    "                                            default_initializer = paddle.nn.initializer.Uniform(low=0,high=2*np.pi),\r\n",
    "                                            dtype=dtype,is_bias=False)\r\n",
    "    \r\n",
    "    def forward(self):\r\n",
    "        U = U_theta(self.theta,num_qubits)\r\n",
    "        U_dagger = dagger(U)\r\n",
    "        loss = 1-(0.125*paddle.real(trace(matmul(self.u,U_dagger)))[0])\r\n",
    "        return loss\r\n",
    "    \r\n",
    "    def result(self):\r\n",
    "        return self.theta\r\n",
    "\r\n",
    "loss_list = []\r\n",
    "parameter_list = []\r\n",
    "myLayer = Optimization_exl([theta_size])\r\n",
    "opt = paddle.optimizer.Adam(learning_rate=LR,parameters=myLayer.parameters())\r\n",
    "\r\n",
    "for itr in range(ITR):\r\n",
    "    loss = myLayer()[0]\r\n",
    "    loss.backward()\r\n",
    "    opt.minimize(loss)\r\n",
    "    opt.clear_grad()\r\n",
    "\r\n",
    "    loss_list.append(loss.numpy()[0])\r\n",
    "    parameter_list.append(myLayer.parameters()[0].numpy())\r\n",
    "    if itr % 5 == 0:\r\n",
    "        print('iter:', itr, '  loss: %.4f' % loss.numpy())\r\n",
    "print(loss_list[-1])\r\n",
    "print(myLayer.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0   loss: 0.9774\n",
      "iter: 5   loss: 0.5517\n",
      "iter: 10   loss: 0.2901\n",
      "iter: 15   loss: 0.2762\n",
      "iter: 20   loss: 0.2880\n",
      "iter: 25   loss: 0.2536\n",
      "iter: 30   loss: 0.2330\n",
      "iter: 35   loss: 0.2320\n",
      "iter: 40   loss: 0.2322\n",
      "iter: 45   loss: 0.2296\n",
      "iter: 50   loss: 0.2279\n",
      "iter: 55   loss: 0.2267\n",
      "iter: 60   loss: 0.2261\n",
      "iter: 65   loss: 0.2261\n",
      "iter: 70   loss: 0.2260\n",
      "iter: 75   loss: 0.2260\n",
      "iter: 80   loss: 0.2259\n",
      "iter: 85   loss: 0.2259\n",
      "iter: 90   loss: 0.2259\n",
      "iter: 95   loss: 0.2259\n",
      "0.22584664419782585\n",
      "Parameter containing:\n",
      "Tensor(shape=[12], dtype=float64, place=CPUPlace, stop_gradient=False,\n",
      "       [-0.34302257,  3.79840820,  4.89255843, -0.63279702,  4.65861761,  3.83682412,  4.54703008,  3.37265171,  1.35047891,  0.84161231,  3.96285257,  6.62242478])\n"
     ]
    }
   ],
   "source": [
    "#三量子比特门无结构分解\r\n",
    "\r\n",
    "import math\r\n",
    "import numpy as np\r\n",
    "import paddle\r\n",
    "#from paddle import matmul, transpose, trace\r\n",
    "from paddle_quantum.circuit import UAnsatz\r\n",
    "from paddle_quantum.utils import dagger, random_pauli_str_generator, pauli_str_to_matrix\r\n",
    "from paddle_quantum.state import vec, vec_random, density_op, density_op_random\r\n",
    "theta_size = 12\r\n",
    "num_qubits = 3\r\n",
    "ITR =100\r\n",
    "LR=0.5\r\n",
    "SEED = 1\r\n",
    "paddle.seed(SEED)\r\n",
    "path = '飞桨常规赛：量子电路合成/Question_4_Unitary.txt'\r\n",
    "def readfile(path):\r\n",
    "    f = np.loadtxt(path)\r\n",
    "    return f\r\n",
    "\r\n",
    "def U_theta(theta,num_qubits):\r\n",
    "    cir = UAnsatz(num_qubits)\r\n",
    "    cir.ry(theta[0],0)\r\n",
    "    cir.ry(theta[1],1)\r\n",
    "    cir.ry(theta[2],2)    \r\n",
    "    cir.cnot([0,1])\r\n",
    "    cir.cnot([1,2])\r\n",
    "    cir.ry(theta[3],0)\r\n",
    "    cir.ry(theta[4],1)\r\n",
    "    cir.ry(theta[5],2)\r\n",
    "    cir.cnot([0,1])\r\n",
    "    cir.cnot([1,2])\r\n",
    "    cir.ry(theta[6],0)\r\n",
    "    cir.ry(theta[7],1)\r\n",
    "    cir.ry(theta[8],2)\r\n",
    "    cir.cnot([0,1])\r\n",
    "    cir.cnot([1,2])\r\n",
    "    cir.ry(theta[9],0)\r\n",
    "    cir.ry(theta[10],1)\r\n",
    "    cir.ry(theta[11],2)\r\n",
    "    cir.cnot([0,1])\r\n",
    "    cir.cnot([1,2])\r\n",
    "\r\n",
    "    return cir.U\r\n",
    "\r\n",
    "class Optimization_exl(paddle.nn.Layer):\r\n",
    "    def __init__(self,shape,dtype='float64'):\r\n",
    "        super(Optimization_exl,self).__init__()\r\n",
    "        f = readfile(path)\r\n",
    "        self.u = paddle.to_tensor(f)\r\n",
    "        self.theta = self.create_parameter(shape=shape,\r\n",
    "                                            default_initializer = paddle.nn.initializer.Uniform(low=0,high=2*np.pi),\r\n",
    "                                            dtype=dtype,is_bias=False)\r\n",
    "    \r\n",
    "    def forward(self):\r\n",
    "        U = U_theta(self.theta,num_qubits)\r\n",
    "        U_dagger = dagger(U)\r\n",
    "        loss = 1-(0.125*paddle.real(trace(matmul(self.u,U_dagger)))[0])\r\n",
    "        return loss\r\n",
    "    \r\n",
    "    def result(self):\r\n",
    "        return self.theta\r\n",
    "\r\n",
    "loss_list = []\r\n",
    "parameter_list = []\r\n",
    "myLayer = Optimization_exl([theta_size])\r\n",
    "opt = paddle.optimizer.Adam(learning_rate=LR,parameters=myLayer.parameters())\r\n",
    "\r\n",
    "for itr in range(ITR):\r\n",
    "    loss = myLayer()[0]\r\n",
    "    loss.backward()\r\n",
    "    opt.minimize(loss)\r\n",
    "    opt.clear_grad()\r\n",
    "\r\n",
    "    loss_list.append(loss.numpy()[0])\r\n",
    "    parameter_list.append(myLayer.parameters()[0].numpy())\r\n",
    "    if itr % 5 == 0:\r\n",
    "        print('iter:', itr, '  loss: %.4f' % loss.numpy())\r\n",
    "print(loss_list[-1])\r\n",
    "print(myLayer.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0   loss: 0.9833\n",
      "iter: 5   loss: 0.6137\n",
      "iter: 10   loss: 0.5062\n",
      "iter: 15   loss: 0.4351\n",
      "iter: 20   loss: 0.3789\n",
      "iter: 25   loss: 0.3600\n",
      "iter: 30   loss: 0.3493\n",
      "iter: 35   loss: 0.3422\n",
      "iter: 40   loss: 0.3292\n",
      "iter: 45   loss: 0.3246\n",
      "iter: 50   loss: 0.3169\n",
      "iter: 55   loss: 0.2998\n",
      "iter: 60   loss: 0.2780\n",
      "iter: 65   loss: 0.2746\n",
      "iter: 70   loss: 0.2611\n",
      "iter: 75   loss: 0.2532\n",
      "iter: 80   loss: 0.2538\n",
      "iter: 85   loss: 0.2520\n"
     ]
    }
   ],
   "source": [
    "#四量子比特门无结构分解\r\n",
    "\r\n",
    "import math\r\n",
    "import numpy as np\r\n",
    "import paddle\r\n",
    "#from paddle import matmul, transpose, trace\r\n",
    "from paddle_quantum.circuit import UAnsatz\r\n",
    "from paddle_quantum.utils import dagger, random_pauli_str_generator, pauli_str_to_matrix\r\n",
    "from paddle_quantum.state import vec, vec_random, density_op, density_op_random\r\n",
    "theta_size = 40\r\n",
    "num_qubits = 4\r\n",
    "ITR =100\r\n",
    "LR=0.5\r\n",
    "SEED = 1\r\n",
    "paddle.seed(SEED)\r\n",
    "path = '飞桨常规赛：量子电路合成/Question_5_Unitary.txt'\r\n",
    "def readfile(path):\r\n",
    "    f = np.loadtxt(path)\r\n",
    "    return f\r\n",
    "\r\n",
    "def U_theta(theta,num_qubits):\r\n",
    "    cir = UAnsatz(num_qubits)\r\n",
    "    for i in range(10):\r\n",
    "        for j in range(4):\r\n",
    "            cir.ry(theta[4*i+j],j)\r\n",
    "            if j<3:\r\n",
    "                cir.cnot([j+1,j])\r\n",
    "        #for j in range(3):\r\n",
    "            #cir.cnot([j,(j+1)])\r\n",
    "    return cir.U\r\n",
    "\r\n",
    "class Optimization_exl(paddle.nn.Layer):\r\n",
    "    def __init__(self,shape,dtype='float64'):\r\n",
    "        super(Optimization_exl,self).__init__()\r\n",
    "        f = readfile(path)\r\n",
    "        self.u = paddle.to_tensor(f)\r\n",
    "        self.theta = self.create_parameter(shape=shape,\r\n",
    "                                            default_initializer = paddle.nn.initializer.Uniform(low=0,high=2*np.pi),\r\n",
    "                                            dtype=dtype,is_bias=False)\r\n",
    "    \r\n",
    "    def forward(self):\r\n",
    "        U = U_theta(self.theta,num_qubits)\r\n",
    "        U_dagger = dagger(U)\r\n",
    "        loss = 1-(0.5*0.125*paddle.real(trace(matmul(self.u,U_dagger)))[0])\r\n",
    "        return loss\r\n",
    "    \r\n",
    "    def result(self):\r\n",
    "        return self.theta\r\n",
    "\r\n",
    "loss_list = []\r\n",
    "parameter_list = []\r\n",
    "myLayer = Optimization_exl([theta_size])\r\n",
    "opt = paddle.optimizer.Adam(learning_rate=LR,parameters=myLayer.parameters())\r\n",
    "\r\n",
    "for itr in range(ITR):\r\n",
    "    loss = myLayer()[0]\r\n",
    "    loss.backward()\r\n",
    "    opt.minimize(loss)\r\n",
    "    opt.clear_grad()\r\n",
    "\r\n",
    "    loss_list.append(loss.numpy()[0])\r\n",
    "    parameter_list.append(myLayer.parameters()[0].numpy())\r\n",
    "    if itr % 5 == 0:\r\n",
    "        print('iter:', itr, '  loss: %.4f' % loss.numpy())\r\n",
    "print(loss_list[-1])\r\n",
    "print(myLayer.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: Question_1_Answer.txt (stored 0%)\r\n",
      "updating: Question_2_Answer.txt (deflated 11%)\r\n",
      "updating: Question_3_Answer.txt (deflated 22%)\r\n",
      "updating: Question_4_Answer.txt (deflated 51%)\r\n",
      "updating: Question_5_Answer.txt (stored 0%)\r\n",
      "updating: Question_6_Answer.txt (stored 0%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip Answer.zip Question_*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.4 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
